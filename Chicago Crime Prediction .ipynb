{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Collecting wget\n  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\nBuilding wheels for collected packages: wget\n  Running setup.py bdist_wheel for wget ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/spark/shared/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\nSuccessfully built wget\n\u001b[31mtensorflow 1.3.0 requires tensorflow-tensorboard<0.2.0,>=0.1.0, which is not installed.\u001b[0m\nInstalling collected packages: wget\nSuccessfully installed wget-3.2\n"
                }
            ], 
            "source": "!pip install wget"
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Collecting py4j==0.10.6\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/08/162710786239aa72bd72bb46c64f2b02f54250412ba928cb373b30699139/py4j-0.10.6-py2.py3-none-any.whl (189kB)\n\u001b[K    100% |################################| 194kB 2.0MB/s eta 0:00:01\n\u001b[31mtensorflow 1.3.0 requires tensorflow-tensorboard<0.2.0,>=0.1.0, which is not installed.\u001b[0m\n\u001b[?25hInstalling collected packages: py4j\nSuccessfully installed py4j-0.10.6\n"
                }
            ], 
            "source": "!pip install py4j==0.10.6"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Collecting tensorflow\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/ad/48395de38c1e07bab85fc3bbec045e11ae49c02a4db0100463dd96031947/tensorflow-1.12.0-cp35-cp35m-manylinux1_x86_64.whl (83.1MB)\n\u001b[K    100% |################################| 83.1MB 298kB/s eta 0:00:01\n\u001b[?25hCollecting termcolor>=1.1.0 (from tensorflow)\n  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\nCollecting tensorboard<1.13.0,>=1.12.0 (from tensorflow)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n\u001b[K    100% |################################| 3.1MB 1.8MB/s eta 0:00:01\n\u001b[?25hCollecting keras-applications>=1.0.6 (from tensorflow)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/85/64c82949765cfb246bbdaf5aca2d55f400f792655927a017710a78445def/Keras_Applications-1.0.7-py2.py3-none-any.whl (51kB)\n\u001b[K    100% |################################| 61kB 1.4MB/s eta 0:00:01\n\u001b[?25hCollecting numpy>=1.13.3 (from tensorflow)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/15/690c13ae714e156491392cdbdbf41b485d23c285aa698239a67f7cfc9e0a/numpy-1.16.1-cp35-cp35m-manylinux1_x86_64.whl (17.2MB)\n\u001b[K    100% |################################| 17.2MB 706kB/s eta 0:00:01\n\u001b[?25hCollecting protobuf>=3.6.1 (from tensorflow)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/d4/db7296a1407cad69f043537ba1e05afab3646451a066ead7a314d8714388/protobuf-3.6.1-cp35-cp35m-manylinux1_x86_64.whl (1.1MB)\n\u001b[K    100% |################################| 1.1MB 2.4MB/s eta 0:00:01\n\u001b[?25hCollecting grpcio>=1.8.6 (from tensorflow)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/72/dbdce5ba0eb2ee22069430f1c18c2fef22b4f6ffbf188ab2d416695f3992/grpcio-1.18.0-cp35-cp35m-manylinux1_x86_64.whl (10.6MB)\n\u001b[K    100% |################################| 10.6MB 1.1MB/s eta 0:00:01\n\u001b[?25hCollecting wheel>=0.26 (from tensorflow)\n  Downloading https://files.pythonhosted.org/packages/96/ba/a4702cbb6a3a485239fbe9525443446203f00771af9ac000fa3ef2788201/wheel-0.33.1-py2.py3-none-any.whl\nCollecting six>=1.10.0 (from tensorflow)\n  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\nCollecting absl-py>=0.1.6 (from tensorflow)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/bc/ab68120d1d89ae23b694a55fe2aece2f91194313b71f9b05a80b32d3c24b/absl-py-0.7.0.tar.gz (96kB)\n\u001b[K    100% |################################| 102kB 2.2MB/s ta 0:00:01\n\u001b[?25hCollecting keras-preprocessing>=1.0.5 (from tensorflow)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/bf/0315ef6a9fd3fc2346e85b0ff1f5f83ca17073f2c31ac719ab2e4da0d4a3/Keras_Preprocessing-1.0.9-py2.py3-none-any.whl (59kB)\n\u001b[K    100% |################################| 61kB 1.4MB/s eta 0:00:01\n\u001b[?25hCollecting gast>=0.2.0 (from tensorflow)\n  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\nCollecting astor>=0.6.0 (from tensorflow)\n  Downloading https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl\nCollecting markdown>=2.6.8 (from tensorboard<1.13.0,>=1.12.0->tensorflow)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/6b/5600647404ba15545ec37d2f7f58844d690baf2f81f3a60b862e48f29287/Markdown-3.0.1-py2.py3-none-any.whl (89kB)\n\u001b[K    100% |################################| 92kB 1.7MB/s eta 0:00:01\n\u001b[?25hCollecting werkzeug>=0.11.10 (from tensorboard<1.13.0,>=1.12.0->tensorflow)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/c4/12e3e56473e52375aa29c4764e70d1b8f3efa6682bef8d0aae04fe335243/Werkzeug-0.14.1-py2.py3-none-any.whl (322kB)\n\u001b[K    100% |################################| 327kB 1.9MB/s eta 0:00:01\n\u001b[?25hCollecting h5py (from keras-applications>=1.0.6->tensorflow)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/77/c4933e12dca0f61bcdafc207c7532e1250b8d12719459fd85132f3daa9fd/h5py-2.9.0-cp35-cp35m-manylinux1_x86_64.whl (2.8MB)\n\u001b[K    100% |################################| 2.8MB 1.5MB/s eta 0:00:01\n\u001b[?25hCollecting setuptools (from protobuf>=3.6.1->tensorflow)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/6a/4b2fcefd2ea0868810e92d519dacac1ddc64a2e53ba9e3422c3b62b378a6/setuptools-40.8.0-py2.py3-none-any.whl (575kB)\n\u001b[K    100% |################################| 583kB 1.9MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: termcolor, absl-py, gast\n  Running setup.py bdist_wheel for termcolor ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/spark/shared/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n  Running setup.py bdist_wheel for absl-py ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/spark/shared/.cache/pip/wheels/90/db/f8/2c3101f72ef1ad434e4662853174126ce30201a3e163dcbeca\n  Running setup.py bdist_wheel for gast ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/spark/shared/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\nSuccessfully built termcolor absl-py gast\nInstalling collected packages: termcolor, numpy, six, grpcio, wheel, markdown, werkzeug, setuptools, protobuf, tensorboard, h5py, keras-applications, absl-py, keras-preprocessing, gast, astor, tensorflow\nSuccessfully installed absl-py-0.7.0 astor-0.7.1 gast-0.2.2 grpcio-1.18.0 h5py-2.9.0 keras-applications-1.0.7 keras-preprocessing-1.0.9 markdown-3.0.1 numpy-1.16.1 protobuf-3.6.1 setuptools-40.8.0 six-1.12.0 tensorboard-1.12.2 tensorflow-1.12.0 termcolor-1.1.0 werkzeug-0.14.1 wheel-0.33.1\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\n"
                }
            ], 
            "source": "!pip install tensorflow"
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Collecting pyspark\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/01/a37e827c2d80c6a754e40e99b9826d978b55254cc6c6672b5b08f2e18a7f/pyspark-2.4.0.tar.gz (213.4MB)\n\u001b[K    100% |################################| 213.4MB 92kB/s  eta 0:00:01.9MB 47.7MB/s eta 0:00:01\n\u001b[?25hCollecting py4j==0.10.7 (from pyspark)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n\u001b[K    100% |################################| 204kB 2.7MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: pyspark\n  Running setup.py bdist_wheel for pyspark ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/spark/shared/.cache/pip/wheels/cd/54/c2/abfcc942eddeaa7101228ebd6127a30dbdf903c72db4235b23\nSuccessfully built pyspark\nInstalling collected packages: py4j, pyspark\nSuccessfully installed py4j-0.10.7 pyspark-2.4.0\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3/py4j already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n\u001b[33mTarget directory /home/spark/shared/user-libs/python3/share already exists. Specify --upgrade to force replacement.\u001b[0m\n"
                }
            ], 
            "source": "!pip install pyspark"
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 6, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[Row(ID=10642781, Case Number='HZ394208', Date='08/15/2016 11:15:00 AM', Block='061XX W GRAND AVE', IUCR='0460', Primary Type='BATTERY', Description='SIMPLE', Location Description='APARTMENT', Arrest=False, Domestic=False, Beat=2512, District=25, Ward=29, Community Area=19, FBI Code='08B', X Coordinate=1134907, Y Coordinate=1914405, Year=2016, Updated On='02/10/2018 03:50:01 PM', Latitude=41.921319589, Longitude=-87.779748093, Location='(41.921319589, -87.779748093)'),\n Row(ID=10642782, Case Number='HZ394162', Date='08/16/2016 10:17:00 AM', Block='009XX W 58TH ST', IUCR='0820', Primary Type='THEFT', Description='$500 AND UNDER', Location Description='SIDEWALK', Arrest=False, Domestic=True, Beat=712, District=7, Ward=16, Community Area=68, FBI Code='06', X Coordinate=1171050, Y Coordinate=1866373, Year=2016, Updated On='02/10/2018 03:50:01 PM', Latitude=41.788798848, Longitude=-87.648357712, Location='(41.788798848, -87.648357712)'),\n Row(ID=10642783, Case Number='HZ394180', Date='08/15/2016 10:00:00 PM', Block='070XX S ADA ST', IUCR='0890', Primary Type='THEFT', Description='FROM BUILDING', Location Description='RESIDENCE', Arrest=False, Domestic=False, Beat=734, District=7, Ward=17, Community Area=67, FBI Code='06', X Coordinate=1168542, Y Coordinate=1858171, Year=2016, Updated On='02/10/2018 03:50:01 PM', Latitude=41.766346009, Longitude=-87.657789909, Location='(41.766346009, -87.657789909)'),\n Row(ID=10642787, Case Number='HZ394193', Date='08/11/2016 09:00:00 AM', Block='023XX W MOFFAT ST', IUCR='0917', Primary Type='MOTOR VEHICLE THEFT', Description='CYCLE, SCOOTER, BIKE W-VIN', Location Description='STREET', Arrest=False, Domestic=False, Beat=1434, District=14, Ward=1, Community Area=22, FBI Code='07', X Coordinate=1160677, Y Coordinate=1912313, Year=2016, Updated On='02/10/2018 03:50:01 PM', Latitude=41.915083455, Longitude=-87.685120419, Location='(41.915083455, -87.685120419)'),\n Row(ID=10642788, Case Number='HZ394160', Date='08/16/2016 09:20:00 AM', Block='013XX W LAKE ST', IUCR='0460', Primary Type='BATTERY', Description='SIMPLE', Location Description='COMMERCIAL / BUSINESS OFFICE', Arrest=False, Domestic=False, Beat=1224, District=12, Ward=27, Community Area=28, FBI Code='08B', X Coordinate=1167667, Y Coordinate=1901571, Year=2016, Updated On='02/10/2018 03:50:01 PM', Latitude=41.885458855, Longitude=-87.659749904, Location='(41.885458855, -87.659749904)')]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "root\n |-- ID: integer (nullable = true)\n |-- Case Number: string (nullable = true)\n |-- Date: string (nullable = true)\n |-- Block: string (nullable = true)\n |-- IUCR: string (nullable = true)\n |-- Primary Type: string (nullable = true)\n |-- Description: string (nullable = true)\n |-- Location Description: string (nullable = true)\n |-- Arrest: boolean (nullable = true)\n |-- Domestic: boolean (nullable = true)\n |-- Beat: integer (nullable = true)\n |-- District: integer (nullable = true)\n |-- Ward: integer (nullable = true)\n |-- Community Area: integer (nullable = true)\n |-- FBI Code: string (nullable = true)\n |-- X Coordinate: integer (nullable = true)\n |-- Y Coordinate: integer (nullable = true)\n |-- Year: integer (nullable = true)\n |-- Updated On: string (nullable = true)\n |-- Latitude: double (nullable = true)\n |-- Longitude: double (nullable = true)\n |-- Location: string (nullable = true)\n\n"
                }
            ], 
            "source": "df_data_2.printSchema()"
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+--------+-----------+--------------------+--------------------+----+-------------------+--------------------+--------------------+------+--------+----+--------+----+--------------+--------+------------+------------+----+--------------------+------------+-------------+--------------------+\n|      ID|Case Number|                Date|               Block|IUCR|       Primary Type|         Description|Location Description|Arrest|Domestic|Beat|District|Ward|Community Area|FBI Code|X Coordinate|Y Coordinate|Year|          Updated On|    Latitude|    Longitude|            Location|\n+--------+-----------+--------------------+--------------------+----+-------------------+--------------------+--------------------+------+--------+----+--------+----+--------------+--------+------------+------------+----+--------------------+------------+-------------+--------------------+\n|10642781|   HZ394208|08/15/2016 11:15:...|   061XX W GRAND AVE|0460|            BATTERY|              SIMPLE|           APARTMENT| false|   false|2512|      25|  29|            19|     08B|     1134907|     1914405|2016|02/10/2018 03:50:...|41.921319589|-87.779748093|(41.921319589, -8...|\n|10642782|   HZ394162|08/16/2016 10:17:...|     009XX W 58TH ST|0820|              THEFT|      $500 AND UNDER|            SIDEWALK| false|    true| 712|       7|  16|            68|      06|     1171050|     1866373|2016|02/10/2018 03:50:...|41.788798848|-87.648357712|(41.788798848, -8...|\n|10642783|   HZ394180|08/15/2016 10:00:...|      070XX S ADA ST|0890|              THEFT|       FROM BUILDING|           RESIDENCE| false|   false| 734|       7|  17|            67|      06|     1168542|     1858171|2016|02/10/2018 03:50:...|41.766346009|-87.657789909|(41.766346009, -8...|\n|10642787|   HZ394193|08/11/2016 09:00:...|   023XX W MOFFAT ST|0917|MOTOR VEHICLE THEFT|CYCLE, SCOOTER, B...|              STREET| false|   false|1434|      14|   1|            22|      07|     1160677|     1912313|2016|02/10/2018 03:50:...|41.915083455|-87.685120419|(41.915083455, -8...|\n|10642788|   HZ394160|08/16/2016 09:20:...|     013XX W LAKE ST|0460|            BATTERY|              SIMPLE|COMMERCIAL / BUSI...| false|   false|1224|      12|  27|            28|     08B|     1167667|     1901571|2016|02/10/2018 03:50:...|41.885458855|-87.659749904|(41.885458855, -8...|\n|10642794|   HZ394154|08/11/2016 12:00:...|  016XX N TALMAN AVE|0610|           BURGLARY|      FORCIBLE ENTRY|           RESIDENCE| false|   false|1421|      14|   1|            24|      05|     1158449|     1910839|2016|02/10/2018 03:50:...|  41.9110846|-87.693346257|(41.9110846, -87....|\n|10642795|   HZ394197|08/14/2016 04:00:...|  053XX N MANILA AVE|0915|MOTOR VEHICLE THEFT|TRUCK, BUS, MOTOR...|              STREET| false|   false|1622|      16|  45|            11|      07|     1136687|     1935289|2016|02/10/2018 03:50:...|41.978595672|-87.772705899|(41.978595672, -8...|\n|10642796|   HZ394165|08/16/2016 09:30:...|    010XX W 109TH ST|0820|              THEFT|      $500 AND UNDER|              STREET| false|   false|2234|      22|  34|            75|      06|     1171346|     1832531|2016|02/10/2018 03:50:...|41.695925355|-87.648260238|(41.695925355, -8...|\n|10642800|   HZ394230|08/16/2016 11:15:...|  065XX S KEDZIE AVE|1152| DECEPTIVE PRACTICE|ILLEGAL USE CASH ...|         GAS STATION| false|   false| 831|       8|  15|            66|      11|     1156172|     1861266|2016|02/10/2018 03:50:...|41.775096813|-87.703047685|(41.775096813, -8...|\n|10642801|   HZ394196|08/16/2016 05:00:...|  053XX S DREXEL AVE|5002|      OTHER OFFENSE|OTHER VEHICLE OFF...|              STREET| false|    true| 233|       2|   4|            41|      26|     1183145|     1869983|2016|02/10/2018 03:50:...|41.798432007|-87.603897688|(41.798432007, -8...|\n|10642802|   HZ394202|08/16/2016 10:40:...|     064XX W 53RD ST|0560|            ASSAULT|              SIMPLE|              STREET| false|   false| 811|       8|  23|            56|     08A|     1134436|     1868747|2016|02/10/2018 03:50:...|41.796035573|-87.782554857|(41.796035573, -8...|\n|10642803|   HZ394203|07/21/2016 10:00:...|010XX N RIDGEWAY AVE|0890|              THEFT|       FROM BUILDING|           APARTMENT| false|   false|1112|      11|  27|            23|      06|     1151192|     1906664|2016|02/10/2018 03:50:...|41.899773491|-87.720115776|(41.899773491, -8...|\n|10642811|   HZ394052|08/15/2016 10:00:...|001XX W GARFIELD ...|0820|              THEFT|      $500 AND UNDER|              STREET| false|   false| 225|       2|   3|            68|      06|     1176078|     1868387|2016|02/10/2018 03:50:...|41.794214064| -87.62986147|(41.794214064, -8...|\n|10642818|   HZ394191|08/15/2016 11:00:...|101XX S ST LAWREN...|1320|    CRIMINAL DAMAGE|          TO VEHICLE|RESIDENTIAL YARD ...| false|   false| 511|       5|   9|            49|      14|     1182027|     1837971|2016|02/10/2018 03:50:...|41.710613647|-87.608985953|(41.710613647, -8...|\n|10642819|   HZ394072|08/14/2016 10:00:...|   040XX N MOODY AVE|0810|              THEFT|           OVER $500|            SIDEWALK| false|   false|1624|      16|  38|            15|      06|     1134638|     1926123|2016|02/10/2018 03:50:...|41.953479835|-87.780458811|(41.953479835, -8...|\n|10642821|   HZ394181|08/15/2016 01:54:...|    043XX S WELLS ST|2820|      OTHER OFFENSE|    TELEPHONE THREAT|           RESIDENCE| false|   false| 925|       9|   3|            37|      26|     1175335|     1876232|2016|02/10/2018 03:50:...| 41.81575815|-87.632351383|(41.81575815, -87...|\n|10642822|   HZ392800|08/14/2016 05:50:...|    048XX S STATE ST|0810|              THEFT|           OVER $500|              STREET| false|   false| 224|       2|   3|            38|      06|     1177087|     1873037|2016|02/10/2018 03:50:...|41.806951386|-87.626021224|(41.806951386, -8...|\n|10642823|   HZ394159|08/16/2016 08:43:...| 042XX N LINCOLN AVE|0460|            BATTERY|              SIMPLE|              STREET| false|   false|1911|      19|  47|             5|     08B|     1161505|     1928056|2016|02/10/2018 03:50:...|41.958265994|-87.681638768|(41.958265994, -8...|\n|10642830|   HZ394118|08/16/2016 09:35:...|   079XX S DAMEN AVE|031A|            ROBBERY|      ARMED: HANDGUN|PARKING LOT/GARAG...| false|   false| 611|       6|  18|            71|      03|     1164404|     1852184|2016|02/10/2018 03:50:...|41.750005014|-87.673125651|(41.750005014, -8...|\n|10642831|   HZ394113|08/16/2016 09:40:...|  052XX S PAULINA ST|0486|            BATTERY|DOMESTIC BATTERY ...|              STREET|  true|   false| 932|       9|  16|            61|     08B|     1165896|     1870050|2016|02/10/2018 03:50:...|41.799000108|-87.667151152|(41.799000108, -8...|\n+--------+-----------+--------------------+--------------------+----+-------------------+--------------------+--------------------+------+--------+----+--------+----+--------------+--------+------------+------------+----+--------------------+------------+-------------+--------------------+\nonly showing top 20 rows\n\n"
                }
            ], 
            "source": "df_data_2.show()"
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+--------------------+\n|        Primary Type|\n+--------------------+\n|OFFENSE INVOLVING...|\n|            STALKING|\n|PUBLIC PEACE VIOL...|\n|           OBSCENITY|\n|NON-CRIMINAL (SUB...|\n|               ARSON|\n|   DOMESTIC VIOLENCE|\n|            GAMBLING|\n|   CRIMINAL TRESPASS|\n|             ASSAULT|\n|      NON - CRIMINAL|\n|LIQUOR LAW VIOLATION|\n| MOTOR VEHICLE THEFT|\n|               THEFT|\n|             BATTERY|\n|             ROBBERY|\n|            HOMICIDE|\n|           RITUALISM|\n|    PUBLIC INDECENCY|\n| CRIM SEXUAL ASSAULT|\n|   HUMAN TRAFFICKING|\n|        INTIMIDATION|\n|        PROSTITUTION|\n|  DECEPTIVE PRACTICE|\n|CONCEALED CARRY L...|\n|         SEX OFFENSE|\n|     CRIMINAL DAMAGE|\n|           NARCOTICS|\n|        NON-CRIMINAL|\n|       OTHER OFFENSE|\n|          KIDNAPPING|\n|            BURGLARY|\n|   WEAPONS VIOLATION|\n|OTHER NARCOTIC VI...|\n|INTERFERENCE WITH...|\n+--------------------+\n\n"
                }
            ], 
            "source": "df_data_2.select('Primary Type').distinct().show(40)"
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 10, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "6813181"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "df_data_2.count()"
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Number of training records: 5449776\nNumber of testing records : 1227158\nNumber of prediction records : 136247\n"
                }
            ], 
            "source": "splitted_data = df_data_2.randomSplit([0.8, 0.18, 0.02], 24)\ntrain_data = splitted_data[0]\ntest_data = splitted_data[1]\npredict_data = splitted_data[2]\n\nprint(\"Number of training records: \" + str(train_data.count()))\nprint(\"Number of testing records : \" + str(test_data.count()))\nprint(\"Number of prediction records : \" + str(predict_data.count()))"
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from pyspark.ml.feature import OneHotEncoder, StringIndexer, IndexToString, VectorAssembler\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml import Pipeline, Model"
        }, 
        {
            "execution_count": 13, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "stringIndexer_label = StringIndexer(inputCol=\"Primary Type\", outputCol=\"label\", handleInvalid=\"keep\").fit(df_data_2)\nstringIndexer_des = StringIndexer(inputCol=\"Description\", outputCol=\"Description_IX\", handleInvalid=\"keep\")\nstringIndexer_locdes = StringIndexer(inputCol=\"Location Description\", outputCol=\"Location_Description_IX\", handleInvalid=\"keep\")"
        }, 
        {
            "execution_count": 14, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "vectorAssembler_features = VectorAssembler(inputCols=[\"Description_IX\", \"Location_Description_IX\", \"Year\"], outputCol=\"features\")"
        }, 
        {
            "execution_count": 15, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")"
        }, 
        {
            "execution_count": 16, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=stringIndexer_label.labels)"
        }, 
        {
            "execution_count": 17, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "pipeline_rf = Pipeline(stages=[stringIndexer_label, stringIndexer_des, stringIndexer_locdes, vectorAssembler_features, rf, labelConverter])"
        }, 
        {
            "execution_count": 18, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "root\n |-- ID: integer (nullable = true)\n |-- Case Number: string (nullable = true)\n |-- Date: string (nullable = true)\n |-- Block: string (nullable = true)\n |-- IUCR: string (nullable = true)\n |-- Primary Type: string (nullable = true)\n |-- Description: string (nullable = true)\n |-- Location Description: string (nullable = true)\n |-- Arrest: boolean (nullable = true)\n |-- Domestic: boolean (nullable = true)\n |-- Beat: integer (nullable = true)\n |-- District: integer (nullable = true)\n |-- Ward: integer (nullable = true)\n |-- Community Area: integer (nullable = true)\n |-- FBI Code: string (nullable = true)\n |-- X Coordinate: integer (nullable = true)\n |-- Y Coordinate: integer (nullable = true)\n |-- Year: integer (nullable = true)\n |-- Updated On: string (nullable = true)\n |-- Latitude: double (nullable = true)\n |-- Longitude: double (nullable = true)\n |-- Location: string (nullable = true)\n\n"
                }
            ], 
            "source": "train_data.printSchema()"
        }, 
        {
            "execution_count": 19, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "ename": "IllegalArgumentException", 
                    "evalue": "'requirement failed: DecisionTree requires maxBins (= 32) to be at least as large as the number of values in each categorical feature, but categorical feature 0 has 381 values. Considering remove this and other categorical features with a large number of values, or add more training examples.'", 
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", 
                        "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)", 
                        "\u001b[0;32m/opt/ibm/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/opt/ibm/spark/python/lib/py4j-0.10.6-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o144.fit.\n: java.lang.IllegalArgumentException: requirement failed: DecisionTree requires maxBins (= 32) to be at least as large as the number of values in each categorical feature, but categorical feature 0 has 381 values. Considering remove this and other categorical features with a large number of values, or add more training examples.\n\tat scala.Predef$.require(Predef.scala:224)\n\tat org.apache.spark.ml.tree.impl.DecisionTreeMetadata$.buildMetadata(DecisionTreeMetadata.scala:137)\n\tat org.apache.spark.ml.tree.impl.RandomForest$.run(RandomForest.scala:105)\n\tat org.apache.spark.ml.classification.RandomForestClassifier.train(RandomForestClassifier.scala:139)\n\tat org.apache.spark.ml.classification.RandomForestClassifier.train(RandomForestClassifier.scala:45)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:118)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:82)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:508)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:811)\n", 
                        "\nDuring handling of the above exception, another exception occurred:\n", 
                        "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-19-c2a388530c85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_rf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline_rf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", 
                        "\u001b[0;32m/opt/ibm/spark/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n", 
                        "\u001b[0;32m/opt/ibm/spark/python/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    107\u001b[0m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# must be an Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mindexOfLastEstimator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/opt/ibm/spark/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n", 
                        "\u001b[0;32m/opt/ibm/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/opt/ibm/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \"\"\"\n\u001b[1;32m    284\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/opt/ibm/spark/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1160\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/opt/ibm/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;31mIllegalArgumentException\u001b[0m: 'requirement failed: DecisionTree requires maxBins (= 32) to be at least as large as the number of values in each categorical feature, but categorical feature 0 has 381 values. Considering remove this and other categorical features with a large number of values, or add more training examples.'"
                    ], 
                    "output_type": "error"
                }
            ], 
            "source": "model_rf = pipeline_rf.fit(train_data)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "predictions = model_rf.transform(test_data)\nevaluatorRF = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluatorRF.evaluate(predictions)\n\nprint(\"Accuracy = %g\" % accuracy)\nprint(\"Test Error = %g\" % (1.0 - accuracy))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from repository.mlrepositoryclient import MLRepositoryClient\nfrom repository.mlrepositoryartifact import MLRepositoryArtifact"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "ml_repository_client = MLRepositoryClient(service_path)\nml_repository_client.authorize(username, password)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "model_artifact = MLRepositoryArtifact(model_rf, training_data = train_data, name=\"Crime Line prediction\")"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "saved_model = ml_repository_client.models.save(model_artifact)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "saved_model.meta.available_props()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "print (\"modelType: \" + saved_model.meta.prop(\"modelType\"))\nprint (\"trainingDataSchema: \" + str(saved_model.meta.prop(\"trainingDataSchema\")))\nprint (\"creationTime: \" + str(saved_model.meta.prop(\"creationTime\")))\nprint (\"modelVersionHref: \" + saved_model.meta.prop(\"modelVersionHref\"))\nprint (\"label: \" + saved_model.meta.prop(\"label\"))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "loadedModelArtifact = ml_repository_client.models.get(saved_model.uid)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "print (loadedModelArtifact.name)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "predictions = loadedModelArtifact.model_instance().transform(predict_data)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "predictions.show(5)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "predictions.select(\"predictedLabel\").groupBy(\"predictedLabel\").count().show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!pip install plotly --user"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!pip install cufflinks==0.8.2"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import sys\nimport pandas\nimport plotly.plotly as py\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport cufflinks as cf\nimport plotly.graph_objs as go\ninit_notebook_mode(connected=True)\nsys.path.append(\"\".join([os.environ[\"HOME\"]]))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "predictions_pdf = predictions.select(\"prediction\", \"predictedLabel\", \"Description\", \"Location Description\", \"Year\").toPandas()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "cumulative_stats = predictions_pdf.groupby(['predictedLabel']).count()\ncrime_data = [go.Pie(labels=cumulative_stats.index, values=cumulative_stats['Description'])]\ncrime_layout = go.Layout(title='Predicted crime line rate in Chicago from 2001- Present')\n\nfig = go.Figure(data=crime_data, layout=crime_layout)\niplot(fig)"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark", 
            "name": "python3", 
            "language": "python3"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}